\# ğŸš€ AnomaLens - Real-time Anomaly Detection System



A production-ready anomaly detection API for IoT sensor data with real-time monitoring, alerting, and MLOps capabilities.



\## âœ¨ Features



\- \*\*Real-time Anomaly Detection\*\*: Detect anomalies in streaming sensor data

\- \*\*RESTful API\*\*: Fully documented FastAPI endpoints

\- \*\*Multiple Algorithms\*\*: Isolation Forest, One-Class SVM, Local Outlier Factor

\- \*\*WebSocket Support\*\*: Real-time anomaly alerts

\- \*\*Dashboard\*\*: Interactive web dashboard

\- \*\*Model Management\*\*: Versioning, training, and evaluation

\- \*\*Monitoring\*\*: System metrics and health checks

\- \*\*Alert System\*\*: Email/Slack/Teams notifications

\- \*\*Docker Support\*\*: Easy deployment with Docker Compose



\## ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ Sensors â”‚â”€â”€â”€â”€â–¶â”‚ Kafka â”‚â”€â”€â”€â”€â–¶â”‚ PySpark â”‚

â”‚ (IoT) â”‚ â”‚ (Stream) â”‚ â”‚ (Processing)â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ Grafana â”‚â—€â”€â”€â”€â”€â”‚ FastAPI â”‚â—€â”€â”€â”€â”€â”‚ Models â”‚

â”‚ (Dashboard) â”‚ â”‚ (API) â”‚ â”‚ (ML) â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜





\## ğŸš€ Quick Start



\### 1. Installation



```bash

\# Clone repository

git clone https://github.com/yourusername/AnomaLens.git

cd AnomaLens



\# Create virtual environment

python -m venv venv

source venv/bin/activate  # On Windows: venv\\Scripts\\activate



\# Install dependencies

pip install -r requirements.txt





2\. Start the API



\# Run the FastAPI server

python -m api.main





The API will be available at: http://localhost:8000





3\. Access the Dashboard

Open your browser and go to: http://localhost:8000/dashboard



4\. Test the API



\# Run the test suite

python test\_api.py





ğŸ“š API Documentation

Interactive Docs

Swagger UI: http://localhost:8000/docs



ReDoc: http://localhost:8000/redoc





Key Endpoints





Method	Endpoint	Description

GET	/health	Health check

POST	/api/v1/predict	Single prediction

POST	/api/v1/predict/batch	Batch prediction

GET	/api/v1/model	Model information

POST	/api/v1/model/train	Train new model

GET	/api/v1/alerts	Recent alerts

GET	/api/v1/metrics	System metrics

WS	/ws	WebSocket for real-time updates





ğŸ”§ Configuration



Create a .env file:



\# API Settings

HOST=0.0.0.0

PORT=8000

DEBUG=True



\# Model Settings

MODEL\_PATH=models/anomaly\_detector.joblib

MODEL\_TYPE=isolation\_forest

DEFAULT\_CONTAMINATION=0.1



\# Alert Settings

ALERT\_THRESHOLD\_CRITICAL=0.8

ALERT\_THRESHOLD\_WARNING=0.6



\# Email Settings (for alerts)

SMTP\_SERVER=smtp.gmail.com

SMTP\_PORT=587

SMTP\_USERNAME=your\_email@gmail.com

SMTP\_PASSWORD=your\_password





ğŸ³ Docker Deployment



\# Build and run with Docker Compose

docker-compose up --build



\# Run in background

docker-compose up -d



\# View logs

docker-compose logs -f



\# Stop services

docker-compose down





ğŸ“Š Monitoring \& Observability



Built-in Monitoring

Health checks: /health endpoint



Metrics: /api/v1/metrics endpoint



Logging: Structured logs in logs/ directory



External Integrations

Prometheus: Metrics endpoint at /metrics (port 9090)



Grafana: Pre-built dashboards available



MLflow: Experiment tracking at http://localhost:5000



ğŸ¤– MLOps Features

Model Management

Automatic model versioning



Training history tracking



Performance metrics logging



A/B testing support



Automated Pipeline

Data collection and validation



Feature engineering



Model training and evaluation



Model deployment and serving



Monitoring and retraining



ğŸ§ª Testing



\# Run unit tests

pytest tests/



\# Run with coverage

pytest --cov=api tests/



\# Run performance tests

python test\_api.py





ğŸ“ˆ Performance

Latency: < 50ms per prediction



Throughput: 1000+ predictions per second



Accuracy: 95%+ on synthetic data



Scalability: Horizontal scaling with Docker



ğŸ”’ Security

CORS configuration



API key authentication (optional)



Input validation with Pydantic



Rate limiting (planned)



HTTPS support (planned)



ğŸ“ Project Structure



AnomaLens/

â”œâ”€â”€ api/                 # FastAPI application

â”‚   â”œâ”€â”€ main.py         # Main app

â”‚   â”œâ”€â”€ models.py       # Pydantic models

â”‚   â”œâ”€â”€ endpoints.py    # API routes

â”‚   â””â”€â”€ dependencies.py # Dependencies

â”œâ”€â”€ core/               # Core logic

â”‚   â”œâ”€â”€ config.py       # Configuration

â”‚   â”œâ”€â”€ anomaly_detector.py # ML models

â”‚   â””â”€â”€ data_generator.py  # Data utilities

â”œâ”€â”€ models/             # Saved models

â”œâ”€â”€ static/dashboard.html      # Static files (dashboard)

â”œâ”€â”€ logs/               # Application logs

â”œâ”€â”€ tests/              # Test suite
    â”œâ”€â”€ test_api.py

    â””â”€â”€ test_pipeline.py

â”œâ”€â”€ docker/             # Docker configurations

â”œâ”€â”€ requirements.txt    # Python dependencies

â”œâ”€â”€ Dockerfile          # Docker image

â”œâ”€â”€ docker-compose.yml  # Docker Compose

â””â”€â”€ README.md           # This file



ğŸš€ Production Deployment

1\. Environment Setup



\# Set production environment

export DEBUG=False

export PORT=80



2\. Database Setup



\# Setup PostgreSQL (optional)

docker run --name anomalens-db -e POSTGRES\_PASSWORD=secret -d postgres



3\. Deploy with Docker



\# Build production image

docker build -t anomalens:latest .



\# Run with production settings

docker run -d -p 80:80 \\

&nbsp; -e DEBUG=False \\

&nbsp; -e DATABASE\_URL=postgresql://user:pass@db:5432/anomalens \\

&nbsp; anomalens:latest





4\. Deploy to Cloud

AWS: ECS/EKS with Fargate



GCP: Cloud Run or GKE



Azure: AKS or App Service



Heroku: Simple one-click deploy



ğŸ¯ Use Cases

1\. Industrial IoT

Predictive maintenance



Equipment monitoring



Quality control



2\. Smart Cities

Traffic pattern analysis



Utility consumption monitoring



Environmental monitoring



3\. Healthcare

Patient monitoring



Medical device tracking



Hospital equipment management



4\. Finance

Fraud detection



Transaction monitoring



Risk assessment



ğŸ¤ Contributing

Fork the repository



Create a feature branch



Make your changes



Add tests



Submit a pull request



ğŸ“„ License

MIT License - see LICENSE file



ğŸ™ Acknowledgments

Built with FastAPI



Machine learning with scikit-learn



Real-time processing with Kafka



Monitoring with Prometheus/Grafana



Containerization with Docker



